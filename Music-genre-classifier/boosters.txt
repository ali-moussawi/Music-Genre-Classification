can be used to boost the performance of any machine learning algorithm. 
It is best used with weak learners. These are models that achieve accuracy just above 
random chance on a classification problem. 
The most suited and therefore most common algorithm used with AdaBoost are decision trees with one level.